% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ns_mgcca.R
\name{ns_mgcca}
\alias{ns_mgcca}
\title{Multiway Generalized Canonical Correlation Analysis (MGCCA)}
\usage{
ns_mgcca(
  A,
  C = 1 - diag(length(A)),
  tau = rep(1, length(A)),
  ncomp = rep(1, length(A)),
  scheme = "centroid",
  scale = TRUE,
  init = "svd",
  bias = TRUE,
  tol = 1e-08,
  verbose = FALSE,
  scale_block = TRUE,
  regularisation_matrices = NULL,
  ranks = rep(1, length(A)),
  prescaling = FALSE,
  quiet = FALSE,
  kronecker_covariance = F,
  n_run = 1,
  n_cores = 1
)
}
\arguments{
\item{A}{A list that contains the \eqn{J} blocks of variables. It could be
either the original matrices (\eqn{X_1, X_2, ..., X_J}).}

\item{C}{A symmetric matrix (J*J) that describes the relationships between
blocks.}

\item{tau}{Either a 1*J vector or a \eqn{\mathrm{max}(ncomp) \times J} matrix
containing the values of the regularization parameters (default: tau = 1,
for each block and each dimension). Tau varies from 0 (maximizing the
correlation) to 1 (maximizing the covariance). If tau = "optimal" the
regularization paramaters are estimated for each block and each dimension
using the Schafer and Strimmer (2005) analytical formula . If tau is a
\eqn{1\times J} vector, tau[j] is identical across the dimensions of block
\eqn{\mathbf{X}_j}. If tau is a matrix, tau[k, j] is associated with
\eqn{\mathbf{X}_{jk}} (\eqn{k}th residual matrix for block \eqn{j}). It can
be estimated by using \link{rgcca_permutation}.}

\item{ncomp}{A vector of length J indicating the number of block components
for each block.}

\item{scheme}{A character string or a function giving the scheme function for
covariance maximization among "horst" (the identity function), "factorial"
 (the squared values), "centroid" (the absolute values). The scheme function
 can be any continously differentiable convex functin and it is possible to
 design explicitely the sheme function (e.g. function(x) x^4) as argument of
 rgcca function.  See (Tenenhaus et al, 2017) for details.}

\item{scale}{A logical value indicating if each block is standardized}

\item{init}{A character giving the mode of initialization to use in the
algorithm. The alternatives are either by Singular Value Decompostion ("svd")
or random ("random") (default: "svd").}

\item{bias}{A logical value for biaised (\eqn{1/n}) or unbiaised
(\eqn{1/(n-1)}) estimator of the var/cov (default: bias = TRUE).}

\item{tol}{The stopping value for the convergence of the algorithm.}

\item{verbose}{A logical value indicating whether the warnings are displayed}

\item{scale_block}{A logical value indicating if each block is divided by
the square root of its number of variables.}

\item{regularisation_matrices}{If not NULL, a list of \eqn{J} elements. Each
element of \eqn{regularisation_matrices} is either NULL or a list of
symmetric positive definite regularization matrices. There must be as many
matrices as modes on the corresponding block and their dimensions must match
the dimensions of the corresponding modes. A change of variable is done at
the beginning and at the end of the MGCCA algorithm to apply regularization.}

\item{ranks}{A vector of \eqn{J} elements that gives the number of terms in
the Kronecker constraint (hence the rank of the estimated tensor) for each
block.}

\item{prescaling}{A logical value indicating if the scaling has been done
outside of the function.}

\item{quiet}{A boolean hidding the warnings}
}
\value{
\item{Y}{A list of \eqn{J} elements. Each element of \eqn{Y} is a
matrix that contains the analysis components for the corresponding block.}

\item{a}{A list of \eqn{J} elements. Each element of \eqn{a} is a
matrix that contains the outer weight vectors for each block.}

\item{astar}{A list of \eqn{J} elements. Each element of astar is a
matrix defined as Y[[j]][, h] = A[[j]]\%*\%astar[[j]][, h]}

\item{factors}{A list of \eqn{J} elements. If bloc \eqn{j} is a
tensor of order \eqn{d}, element \eqn{j} of \eqn{factors} is a list with
\eqn{d} elements and each element is a matrix that contains the outer weight
vectors for each block.}

\item{weights}{A list of \eqn{J} elements. Element \eqn{j}
of \eqn{weights} weights the rank-1 factors.
\eqn{d} elements and each element is a matrix that contains the outer weight
vectors for each block.}

\item{crit}{A vector of integer that contains for each component the
values of the analysis criteria across iterations.}

\item{AVE}{A list of numerical values giving the indicators of model
quality based on the Average Variance Explained (AVE): AVE(for each block),
AVE(outer model), AVE(inner model).}

\item{A}{The eventually preprocessed entry data.}
}
\description{
MGCCA extends RGCCA to address the issue of tensor structured data.
Specifically, RGCCA is combined with a Kronecker constraint that gives rise
to Multiway GCCA (MGCCA) which is implemented in the function mgcca().
Given \eqn{J} arrays \eqn{X_1, X_2, ..., X_J}, that represent
\eqn{J} sets of variables observed on the same set of \eqn{n} individuals.
The arrays \eqn{X_1, X_2, ..., X_J} must have the same dimension on the
first dimension, but may (and usually will) have different numbers of modes
and mode dimensions. Blocks are not necessarily fully connected within the
MGCCA framework. Hence MGCCA requires the construction (user specified) of a
design matrix (\eqn{C}) that characterizes the connections between blocks.
Elements of the symmetric design matrix \eqn{C = (c_{jk})} are equal to 1 if
block \eqn{j} and block \eqn{k} are connected, and 0 otherwise. The MGCCA
algorithm is very similar to the RGCCA algorithm and keeps the same monotone
convergence properties (i.e. the bounded criteria to be maximized increases
at each step of the iterative procedure and hits at convergence a stationary
point).
Moreover, using a deflation strategy, mgcca() enables the computation of
several MGCCA block components (specified by ncomp) for each block. Block
components for each block are guaranteed to be orthogonal when using this
deflation strategy. The so-called symmetric deflation is considered in this
implementation, i.e. each block is deflated with respect to its own
component. Moreover, we stress that the numbers of components per block
could differ from one block to another.
}
\references{
Soon.
}
