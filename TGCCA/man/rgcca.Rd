% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rgcca.R
\name{rgcca}
\alias{rgcca}
\title{Regularized (or Sparse, or Multiway) Generalized Canonical Correlation
Analysis (S/M/RGCCA)}
\usage{
rgcca(
  blocks,
  type = "rgcca",
  scale = TRUE,
  scale_block = TRUE,
  prescaling = FALSE,
  connection = 1 - diag(length(blocks)),
  scheme = "factorial",
  ncomp = rep(1, length(blocks)),
  tau = rep(1, length(blocks)),
  sparsity = rep(1, length(blocks)),
  ranks = rep(1, length(blocks)),
  regularisation_matrices = NULL,
  kronecker_covariance = F,
  init = "svd",
  bias = TRUE,
  tol = 1e-08,
  response = NULL,
  superblock = FALSE,
  method = "nipals",
  verbose = FALSE,
  quiet = TRUE,
  penalty_coef = 0,
  n_run = 1,
  n_cores = 1
)
}
\arguments{
\item{blocks}{A list that contains the J blocks of variables X1, X2, ..., XJ.
Block Xj is a matrix of dimension n x p_j where p_j is the number of
variables in X_j.}

\item{type}{A character string indicating the multi-block component
method to consider: rgcca, sgcca, pca, spca, pls, spls, cca,
ifa, ra, gcca, maxvar, maxvar-b, maxvar-a, mcoa,cpca-1, cpca-2,
cpca-4, hpca, maxbet-b, maxbet, maxdiff-b, maxdiff, maxvar-a,
sabscor, ssqcor, ssqcor, ssqcov-1, ssqcov-2, ssqcov, sumcor,
sumcov-1, sumcov-2, sumcov, sabscov, sabscov-1, sabscov-2.}

\item{scale}{A logical value indicating if each block is standardized}

\item{scale_block}{A logical value indicating if each block is divided by
the square root of its number of variables.}

\item{prescaling}{A logical value indicating if the scaling has been done
outside of the function.}

\item{connection}{A symmetric matrix (J*J) that describes the relationships
between blocks. Elements of the connection matrix must be positive ; but
usually equal to 1 if block \eqn{j} and block \eqn{k} are connected, and 0
otherwise.}

\item{scheme}{A character string or a function giving the scheme function for
covariance maximization among "horst" (the identity function), "factorial"
 (the squared values), "centroid" (the absolute values). The scheme function
 can be any continously differentiable convex functin and it is possible to
 design explicitely the sheme function (e.g. function(x) x^4) as argument of
 rgcca function.  See (Tenenhaus et al, 2017) for details.}

\item{ncomp}{A vector of length J indicating the number of block components
for each block.}

\item{tau}{Either a 1*J vector or a \eqn{\mathrm{max}(ncomp) \times J} matrix
containing the values of the regularization parameters (default: tau = 1,
for each block and each dimension). Tau varies from 0 (maximizing the
correlation) to 1 (maximizing the covariance). If tau = "optimal" the
regularization paramaters are estimated for each block and each dimension
using the Schafer and Strimmer (2005) analytical formula . If tau is a
\eqn{1\times J} vector, tau[j] is identical across the dimensions of block
\eqn{\mathbf{X}_j}. If tau is a matrix, tau[k, j] is associated with
\eqn{\mathbf{X}_{jk}} (\eqn{k}th residual matrix for block \eqn{j}). It can
be estimated by using \link{rgcca_permutation}.}

\item{sparsity}{Either a \eqn{1*J} vector or a \eqn{max(ncomp) * J} matrix 
encoding the L1 constraints applied to the outer weight vectors. The amount 
of sparsity varies between \eqn{1/sqrt(p_j)} and 1 (larger values of sparsity 
correspond to less penalization). If sparsity is a vector, L1-penalties are 
the same for all the weights corresponding to the same block but different 
components: 
\deqn{for all h, |a_{j,h}|_{L_1} \le c_1[j] \sqrt{p_j},}
with \eqn{p_j} the number of variables of \eqn{X_j}.
If sparsity is a matrix, each row \eqn{h} defines the constraints applied to 
the weights corresponding to components \eqn{h}:
\deqn{for all h, |a_{j,h}|_{L_1} \le c_1[h,j] \sqrt{p_j}.} It can be 
estimated by using \link{rgcca_permutation}.}

\item{ranks}{A vector of \eqn{J} elements that gives the number of terms in
the Kronecker constraint (hence the rank of the estimated tensor) for each
block.}

\item{regularisation_matrices}{If not NULL, a list of \eqn{J} elements. Each
element of \eqn{regularisation_matrices} is either NULL or a list of
symmetric positive definite regularization matrices. There must be as many
matrices as modes on the corresponding block and their dimensions must match
the dimensions of the corresponding modes. A change of variable is done at
the beginning and at the end of the MGCCA algorithm to apply regularization.}

\item{init}{A character giving the mode of initialization to use in the
algorithm. The alternatives are either by Singular Value Decompostion ("svd")
or random ("random") (default: "svd").}

\item{bias}{A logical value for biaised (\eqn{1/n}) or unbiaised
(\eqn{1/(n-1)}) estimator of the var/cov (default: bias = TRUE).}

\item{tol}{The stopping value for the convergence of the algorithm.}

\item{response}{An integer giving the position of the response block. When
the response argument is filled the supervised mode is automatically
activated.}

\item{superblock}{Boolean indicating the presence of the superblock.
Default = TRUE}

\item{method}{Either a character corresponding to the used method
("complete","knn","em","sem") or a function taking a list of J blocks (A) as
only parameter and returning the imputed list.
\itemize{
\item{\code{"mean"}}{ corresponds to an imputation by the colmeans}
\item{\code{"complete"}}{ corresponds to run RGCCA only on the complete
subjects (subjects with missing data are removed)}
\item{\code{"nipals"}}{ corresponds to run RGCCA on all available data
(NIPALS algorithm)}
\item{\code{"em"}}{ corresponds to impute the data with EM-type algorithms}
\item{\code{"sem"}}{ corresponds to impute the data with EM-type algorithms
with superblock approach}
\item{\code{"knn1"}}{ corresponds to impute the data with the 1-Nearest
Neighbor. 1 can be replace by another number (such as knn3) to impute with
the 3-Nearest Neighbors.}}}

\item{verbose}{A logical value indicating if the progress of the
algorithm is reported while computing.}

\item{quiet}{A logical value indicating if the warning messages are reported.}
}
\value{
A RGCCA object

\item{Y}{A list of \eqn{J} elements. Each element of the list \eqn{Y}
is a matrix that contains the RGCCA block components for the corresponding
block.}

\item{a}{A list of \eqn{J} elements. Each element of the list \eqn{a}
is a matrix of block weight vectors for the corresponding block.}

\item{astar}{A list of \eqn{J} elements. Each element of astar is a
matrix defined as Y[[j]][, h] = A[[j]]\%*\%astar[[j]][, h].}

\item{tau}{Either a vector of length J or a matrix of dimension
\eqn{\mathrm{max}(ncomp) \times J} containing the values of the shrinkage
parameters. tau varies from 0 (maximizing the correlation) to 1 (maximizing
the covariance). If tau = "optimal" the shrinkage paramaters are estimated
for each block and each dimension using the Schafer and Strimmer (2005)
analytical formula. If tau is a vector of length J, tau[j] is identical
across the dimensions of block \eqn{\mathbf{X}_j}. If tau is a matrix,
tau[k, j] is associated with \eqn{\mathbf{X}_{jk}} (\eqn{k}th residual
matrix of block \eqn{j}). tau can be also estimated using
\link{rgcca_permutation}.}

\item{crit}{A list of vector of length max(ncomp). Each vector of
the list is related to one specific deflation stage and reports the values
of the criterion for this stage across iterations.}

\item{primal_dual}{A \eqn{1 \times J} vector that contains the
formulation ("primal" or "dual") applied to each of the \eqn{J} blocks
within the RGCCA alogrithm.}

\item{AVE}{A list of numerical values giving the indicators of model
quality based on the Average Variance Explained (AVE): AVE(for each block),
AVE(outer model), AVE(inner model).}

\item{A}{A list that contains the J blocks of variables X1, X2, ...,
XJ. Block Xj is a matrix of dimension n x p_j where p_j is the number of
variables in X_j. These blocks are imputed when an imputation strategy is
selected.}

\item{call}{Call of the function}
}
\description{
RGCCA is a generalization of regularized canonical correlation analysis to
three or more sets of variables. SGCCA extends RGCCA to address the issue of
variable selection. MGCCA extends RGCCA to address the issue of tensor
structured data.
}
\details{
Given J matrices \eqn{\mathbf{X_1}, \mathbf{X_2}, ..., \mathbf{X_J}} that
represent \eqn{J} sets of variables observed on the same set of \eqn{n}
individuals. The matrices \eqn{\mathbf{X_1}, \mathbf{X_2}, ..., \mathbf{X_J}}
must have the same number of rows, but may (and usually will) have different
numbers of columns. The aim of RGCCA is to study the relationships between
these \eqn{J} blocks of variables. It constitutes a general framework for
many multi-block data analysis methods (see Tenenhaus and Tenenhaus, 2011 ;
Tenenhaus et al. 2017). It combines the power of multi-block data analysis
methods (maximization of well identified criteria) and the flexibility of
PLS path modeling (the researcher decides which blocks are connected and
which are not). Hence, the use of RGCCA requires the construction (user
specified) of a design matrix, (\eqn{\mathbf{C}}), that characterizes the
connections between blocks. Elements of the (symmetric) design matrix
\eqn{\mathbf{C} = (c_{jk})} are positive (and usually equal to 1 if block
\eqn{j} and block \eqn{k} are connected, and 0 otherwise). The function
rgcca() implements a monotone global convergent algorithm - i.e. the
bounded criteria to be maximized increases at each step of the iterative
procedure and hits, at convergence a stationary point of the RGCCA
optimization problem. Moreover, depending on the dimensionality of each
block \eqn{\mathbf{X}_j}, \eqn{j = 1, \ldots, J}, the primal (when
\eqn{n > p_j}) algorithm or the dual (when \eqn{n < p_j}) algorithm is used
(see Tenenhaus et al. 2015). At last, a deflation strategy is used to compute
several RGCCA block components (specified by ncomp) for each block. Block
components of each block are guaranteed to be orthogonal. The so-called
symmetric deflation is implemented (i.e. each block is deflated with respect
to its own component). It should be noted that the numbers of components
per block can differ from one block to another.
SGCCA extends RGCCA to address the issue of variable selection
(Tenenhaus et al, 2014).
Specifically, RGCCA is combined with an L1-penalty that gives rise to Sparse
GCCA (SGCCA). The SGCCA algorithm is very similar to the RGCCA algorithm and
keeps the same convergence properties (i.e. the bounded criteria to be
maximized increases at each step of the iterative procedure and hits at
convergence a stationary point). Moreover, using a deflation strategy,
sgcca() enables the computation of several SGCCA orthogonal block components
(specified by ncomp) for each block.
MGCCA extends RGCCA to address the issue of tensor structured data.
Specifically, RGCCA is combined with a Kronecker constraint that gives rise
to Multiway GCCA (MGCCA). The MGCCA algorithm is very similar to the RGCCA
algorithm and keeps the same convergence properties (i.e. the bounded
criteria to be maximized increases at each step of the iterative procedure
and hits at convergence a stationary point). Moreover, using a deflation
strategy, mgcca() enables the computation of several MGCCA orthogonal
block components (specified by ncomp) for each block. MGCCA can handle
blocks of variables structured as higher order arrays.
The rgcca() function can handle missing values using a NIPALS type algorithm
(non-linear iterative partial least squares algorithm) described in
(Tenenhaus et al, 2005). Guidelines describing how to use RGCCA in practice
are provided in (Garali et al., 2017).
}
\examples{
####################
# Example 1: RGCCA #
####################
# Create the dataset
data(Russett)
blocks <- list(
  agriculture = Russett[, seq(3)],
  industry = Russett[, 4:5],
  politic = Russett[, 6:11]
)

# Blocks are fully connected, factorial scheme and tau =1 for all blocks is
# used by default
fit.rgcca <- rgcca(
  blocks = blocks, type = "rgcca", connection = 1 - diag(3),
  scheme = "factorial", tau = rep(1, 3)
)
print(fit.rgcca)
plot(fit.rgcca, type = "weight", block = 3)
politic <- as.vector(apply(Russett[, 9:11], 1, which.max))
plot(fit.rgcca, type = "ind", block = 1:2, comp = rep(1, 2), resp = politic)

############################################
# Example 2: RGCCA and multiple components #
############################################
fit.rgcca <- rgcca(blocks,
  type = "rgcca",
  connection = C, superblock = FALSE,
  tau = rep(1, 3), ncomp = c(2, 2, 2),
  scheme = "factorial", verbose = TRUE
)

politic <- as.vector(apply(Russett[, 9:11], 1, which.max))
plot(fit.rgcca,
  type = "ind", block = 1:2,
  comp = rep(1, 2), resp = politic
)

plot(fit.rgcca, type = "ave")
plot(fit.rgcca, type = "network")
plot(fit.rgcca, type = "weight", block = 1)
plot(fit.rgcca, type = "cor")

##################################
# Example 3: Sparse GCCA (SGCCA) #
##################################

# Tune the model to find the best sparsity coefficients (all the blocks are
# connected together)
perm.out <- rgcca_permutation(blocks,
  n_cores = 1,
  par_type = "sparsity", n_perms = 10
)
print(perm.out)
plot(perm.out)

fit.sgcca <- rgcca(blocks, sparsity = perm.out$bestpenalties)
plot(fit.sgcca, type = "network")
plot(fit.sgcca, type = "ave")

# Select the most significant variables
b <- bootstrap(fit.sgcca, n_cores = 1, n_boot = 100)
plot(b, n_cores = 1)

##############################
# Example 3: Supervised mode #
##############################
# Tune the model for explaining the politic block
# (politic connected to the two other blocks)
cv.out <- rgcca_cv(blocks, response = 3, ncomp = 2, n_cores = 1)
print(cv.out)
plot(cv.out)

fit.rgcca <- rgcca(blocks,
  response = 3, ncomp = 2,
  tau = cv.out$bestpenalties
)
plot(fit.rgcca, type = "both")

b <- bootstrap(fit.rgcca, n_cores = 1, n_boot = 10)
plot(b, n_cores = 1)

##########################
# Example 4: Sparse GCCA #
##########################

}
\references{
Garali I, Adanyeguh IM, Ichou F, Perlbarg V, Seyer A, Colsch B,
Moszer I, Guillemot V, Durr A, Mochel F, Tenenhaus A. A strategy for
multimodal data integration: application to biomarkers identification
in spinocerebellar ataxia. Briefings in Bioinformatics. 2018 Nov 27;19(6):1356-1369.

Tenenhaus M., Tenenhaus A. and Groenen P. J. (2017). Regularized
generalized canonical correlation analysis: a framework for sequential
multiblock component methods. Psychometrika, 82(3), 737-777.

Tenenhaus A., Philippe C. and Frouin, V. (2015). Kernel
generalized canonical correlation analysis. Computational Statistics and
Data Analysis, 90, 114-131.

Tenenhaus A., Philippe C., Guillemot V., Le Cao K. A., Grill J.
and Frouin, V., Variable selection for generalized canonical correlation
analysis, Biostatistics, vol. 15, no. 3, pp. 569-583, 2014.

Tenenhaus A. and Tenenhaus M., (2011). Regularized Generalized
Canonical Correlation Analysis, Psychometrika, Vol. 76, Nr 2, pp 257-284.

Schafer J. and Strimmer K. (2005). A shrinkage approach to
large-scale covariance matrix estimation and implications for functional
genomics. Statistical Applications in Genetics and Molecular Biology 4:32.
}
\seealso{
\code{\link[RGCCA]{plot.rgcca}}, \code{\link[RGCCA]{print.rgcca}},
\code{\link[RGCCA]{rgcca_cv_k}},
\code{\link[RGCCA]{rgcca_permutation}}
\code{\link[RGCCA]{rgcca_predict}}
}
